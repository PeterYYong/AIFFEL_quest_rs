{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d67592",
   "metadata": {},
   "source": [
    "## 1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f90eb7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df7b7e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
      "9920512/9916637 [==============================] - 1s 0us/step\n",
      "9928704/9916637 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cornell 대화 데이터 로드 및 전처리\n",
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'cornell_movie_dialogs.zip',\n",
    "    origin='http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip',\n",
    "    extract=True\n",
    ")\n",
    "path_to_dataset = path_to_zip.replace('cornell_movie_dialogs.zip', 'cornell movie-dialogs corpus/')\n",
    "path_to_movie_lines = path_to_dataset + 'movie_lines.txt'\n",
    "path_to_movie_conversations = path_to_dataset + 'movie_conversations.txt'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f667bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "    \"\"\"문장을 소문자로 변환하고 불필요한 문자를 제거\"\"\"\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
    "    return sentence.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f269efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대화 데이터를 로드하고 질문/답변 쌍 생성\n",
    "def load_conversations():\n",
    "    \"\"\"Cornell 대화 데이터를 로드하여 질문/답변 쌍 생성\"\"\"\n",
    "    id2line = {}\n",
    "    with open(path_to_movie_lines, errors='ignore') as file:\n",
    "        lines = file.readlines()\n",
    "    for line in lines:\n",
    "        parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "        id2line[parts[0]] = parts[4]\n",
    "\n",
    "    inputs, outputs = [], []\n",
    "    with open(path_to_movie_conversations, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "        conversation = [line[1:-1] for line in parts[3][1:-1].split(', ')]\n",
    "\n",
    "        for i in range(len(conversation) - 1):\n",
    "            inputs.append(preprocess_sentence(id2line[conversation[i]]))\n",
    "            outputs.append(preprocess_sentence(id2line[conversation[i + 1]]))\n",
    "            if len(inputs) >= 50000:  # 최대 샘플 크기 설정\n",
    "                return inputs, outputs\n",
    "    return inputs, outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb3c60df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "questions, answers = load_conversations()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5edad49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 50000\n",
      "전체 샘플 수 : 50000\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 로드하고 전처리하여 질문을 questions, 답변을 answers에 저장합니다.\n",
    "questions, answers = load_conversations()\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4b1f5c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 22번째 질문 샘플: she's not a...\n",
      "전처리 후의 22번째 답변 샘플: lesbian?  no. i found a picture of jared leto in one of her drawers, so i'm pretty sure she's not harboring same-sex tendencies.\n"
     ]
    }
   ],
   "source": [
    "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[21]))\n",
    "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[21]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37d508f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGPT-1에서는 Byte Pair Encoding (BPE)를 사용하여 서브워드 단위의 토크나이징을 수행하였으나,\\n이번 코드에서는 TensorFlow Datasets의 SubwordTextEncoder를 사용\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토크나이저 설정\n",
    "\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers, target_vocab_size=2**13\n",
    ")\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "\n",
    "'''\n",
    "GPT-1에서는 Byte Pair Encoding (BPE)를 사용하여 서브워드 단위의 토크나이징을 수행하였으나,\n",
    "이번 코드에서는 TensorFlow Datasets의 SubwordTextEncoder를 사용\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9a9e239c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "98db47c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8331]\n",
      "END_TOKEN의 번호 : [8332]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e23dd2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8333\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "af18c1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocabulary size: 8331\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenizer vocabulary size:\", tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c45c9ab1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [781, 8114, 8, 37, 8172, 8121, 8121, 8121]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [7824, 1223, 8138, 8107, 8107, 61, 4304, 4, 336, 10, 1595, 14, 1104, 698, 3263, 263, 16, 71, 14, 107, 2133, 900, 3992, 59, 8180, 8114, 23, 355, 204, 781, 8114, 8, 37, 885, 2289, 8107, 1160, 8120, 1001, 5179, 4214, 342, 8121]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9e5f2f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 40\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "182d90a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 및 패딩 처리\n",
    "\n",
    "# 문장 토큰화 및 패딩 처리\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    \"\"\"토큰화 및 패딩 처리\"\"\"\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "    # Check if inputs are raw strings\n",
    "    if isinstance(inputs[0], str):\n",
    "        for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "            # 정수 인코딩\n",
    "            sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "            sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "            # 최대 길이 초과 샘플 필터링\n",
    "            if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "                tokenized_inputs.append(sentence1)\n",
    "                tokenized_outputs.append(sentence2)\n",
    "    else:\n",
    "        # If inputs are already tokenized\n",
    "        tokenized_inputs = inputs\n",
    "        tokenized_outputs = outputs\n",
    "\n",
    "    # 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding='post'\n",
    "    )\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LENGTH, padding='post'\n",
    "    )\n",
    "\n",
    "    return tokenized_inputs, tokenized_outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "308daf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 토큰화 및 패딩 처리 호출\n",
    "questions, answers = tokenize_and_filter(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "625bab7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8333\n",
      "필터링 후의 질문 샘플 개수: 42376\n",
      "필터링 후의 답변 샘플 개수: 42376\n"
     ]
    }
   ],
   "source": [
    "#questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baf792a",
   "metadata": {},
   "source": [
    "## 2. Positional Encoding 및 Attention Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d232d73",
   "metadata": {},
   "source": [
    "Positional Encoding 클래스\n",
    "\n",
    "위치 정보를 벡터화하여 시퀀스 데이터에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "462068f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        \"\"\"\n",
    "        Positional Encoding을 초기화.\n",
    "        - position: 최대 위치의 개수 (시퀀스 길이)\n",
    "        - d_model: 임베딩 차원\n",
    "        \"\"\"\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        \"\"\"\n",
    "        각 위치와 임베딩 차원에 대한 각도를 계산.\n",
    "        - position: 위치 값\n",
    "        - i: 차원 인덱스\n",
    "        - d_model: 모델 차원\n",
    "        \"\"\"\n",
    "        return position / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        \"\"\"\n",
    "        Sine과 Cosine을 사용하여 위치 인코딩 계산.\n",
    "        - position: 시퀀스 길이\n",
    "        - d_model: 임베딩 차원\n",
    "        \"\"\"\n",
    "        angle_rads = self.get_angles(\n",
    "            np.arange(position)[:, np.newaxis],  # 위치 (행렬 형태)\n",
    "            np.arange(d_model)[np.newaxis, :],  # 임베딩 차원\n",
    "            d_model\n",
    "        )\n",
    "        # 짝수 인덱스에 Sine 적용\n",
    "        sines = np.sin(angle_rads[:, 0::2])\n",
    "        # 홀수 인덱스에 Cosine 적용\n",
    "        cosines = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        # Sine과 Cosine 결합\n",
    "        pos_encoding = np.concatenate([sines, cosines], axis=-1)\n",
    "        pos_encoding = pos_encoding[np.newaxis, ...]  # 배치 차원 추가\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        입력 텐서에 위치 인코딩 추가.\n",
    "        - inputs: 입력 텐서\n",
    "        \"\"\"\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d934646",
   "metadata": {},
   "source": [
    "Scaled Dot-Product Attention\n",
    "\n",
    "Query와 Key의 유사도를 계산하고, Value에 가중치를 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e2290b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    \"\"\"\n",
    "    Scaled Dot-Product Attention 계산.\n",
    "    - query: Query 행렬\n",
    "    - key: Key 행렬\n",
    "    - value: Value 행렬\n",
    "    - mask: 패딩 마스크 (필요 시 적용)\n",
    "\n",
    "    반환값:\n",
    "    - output: 가중치가 적용된 Value 행렬\n",
    "    \"\"\"\n",
    "    # Query와 Key의 내적 계산\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # Key의 차원으로 스케일링\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # 마스크가 있다면 -∞ 값을 추가하여 무시\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # Softmax로 Attention 가중치 계산\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    # Attention 가중치를 Value에 곱함\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be96d5d1",
   "metadata": {},
   "source": [
    "Multi-Head Attention 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0fdfe3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        \"\"\"\n",
    "        Multi-Head Attention 초기화.\n",
    "        - d_model: 모델의 전체 차원\n",
    "        - num_heads: 헤드의 개수\n",
    "        \"\"\"\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # d_model이 num_heads로 나누어떨어지는지 확인\n",
    "        assert d_model % num_heads == 0\n",
    "\n",
    "        # 각 헤드의 차원\n",
    "        self.depth = d_model // num_heads\n",
    "\n",
    "        # Query, Key, Value를 위한 Dense 레이어\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        # 최종 출력 Dense 레이어\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        \"\"\"\n",
    "        입력 텐서를 다중 헤드로 분리.\n",
    "        - inputs: Dense 레이어 출력\n",
    "        - batch_size: 배치 크기\n",
    "        \"\"\"\n",
    "        # (batch_size, seq_len, d_model) -> (batch_size, seq_len, num_heads, depth)\n",
    "        inputs = tf.reshape(inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        # 헤드 축과 시퀀스 축을 교환\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Multi-Head Attention 계산.\n",
    "        - inputs: Query, Key, Value, Mask를 포함한 딕셔너리\n",
    "        \"\"\"\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # Query, Key, Value 생성 및 다중 헤드로 분리\n",
    "        query = self.split_heads(self.query_dense(query), batch_size)\n",
    "        key = self.split_heads(self.key_dense(key), batch_size)\n",
    "        value = self.split_heads(self.value_dense(value), batch_size)\n",
    "\n",
    "        # Scaled Dot-Product Attention 수행\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        # 헤드 통합\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "\n",
    "        # 최종 Dense 레이어 통과\n",
    "        return self.dense(concat_attention)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2605215",
   "metadata": {},
   "source": [
    "## 3. GPT 모델 구현\n",
    "\n",
    "GPT 모델은 Transformer 기반으로 하되, 인코더를 제거하고 디코더만 사용하여 생성 모델로 동작하도록 수정되었습니다. \n",
    "\n",
    "\n",
    "주요 변경 사항:\n",
    "\n",
    "- 인코더 제거: Transformer의 인코더-디코더 구조 중 인코더를 제거하고 디코더만 사용.\n",
    "- Look-Ahead Mask: GPT는 Causal Language Modeling을 위해 Look-Ahead Mask를 적용.\n",
    "- 위치 정보 추가: 입력 데이터에 위치 정보를 추가하는 PositionalEncoding 레이어 구현.\n",
    "- 학습 데이터 전처리: 디코더 입력과 출력 데이터를 시프트하여 구성."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce23552",
   "metadata": {},
   "source": [
    "GPT Decoder Layer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "377f9bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT 모델 디코더 레이어 정의\n",
    "def decoder_layer_gpt(units, d_model, num_heads, dropout):\n",
    "    \"\"\"\n",
    "    GPT의 Decoder Layer를 정의.\n",
    "    - units: Feed Forward 네트워크의 은닉 유닛 크기\n",
    "    - d_model: 임베딩 차원\n",
    "    - num_heads: Multi-Head Attention의 헤드 개수\n",
    "    - dropout: 드롭아웃 비율\n",
    "    \"\"\"\n",
    "    # 입력 텐서 정의\n",
    "    inputs = tf.keras.Input(shape=(None, d_model))  # 입력 임베딩\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None))  # Look-ahead 마스크\n",
    "\n",
    "    # Multi-Head Attention\n",
    "    attention = MultiHeadAttention(d_model, num_heads)(\n",
    "        {'query': inputs, 'key': inputs, 'value': inputs, 'mask': look_ahead_mask}\n",
    "    )\n",
    "    # 잔차 연결과 Layer Normalization\n",
    "    attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + inputs)\n",
    "\n",
    "    # Feed Forward 네트워크\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "\n",
    "    # 잔차 연결과 Layer Normalization\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention)\n",
    "\n",
    "    # 모델 반환\n",
    "    return tf.keras.Model(inputs=[inputs, look_ahead_mask], outputs=outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0d73c8",
   "metadata": {},
   "source": [
    "Look-Ahead Mask 생성 함수\n",
    "\n",
    "Look-ahead Mask는 Transformer에서 미래 정보를 차단하는 데 사용됩니다. 상삼각 행렬로 구성된 마스크는 디코더가 현재 토큰 이후의 정보를 보지 못하게 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "079d0595",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(seq_len):\n",
    "    \"\"\"\n",
    "    Look-ahead 마스크 생성.\n",
    "    - seq_len: 시퀀스 길이\n",
    "    반환값:\n",
    "    - 상삼각 행렬로 이루어진 마스크 텐서\n",
    "    \"\"\"\n",
    "    return 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cfd3ec",
   "metadata": {},
   "source": [
    "GPT 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f7fa5704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_decoder(num_layers, units, d_model, num_heads, dropout, vocab_size, max_seq_len):\n",
    "    \"\"\"\n",
    "    GPT Decoder를 구성.\n",
    "    - num_layers: Decoder Layer의 개수\n",
    "    - units: Feed Forward 네트워크의 은닉 유닛 크기\n",
    "    - d_model: 임베딩 차원\n",
    "    - num_heads: Multi-Head Attention의 헤드 개수\n",
    "    - dropout: 드롭아웃 비율\n",
    "    - vocab_size: 단어 집합 크기\n",
    "    - max_seq_len: 최대 시퀀스 길이\n",
    "    \"\"\"\n",
    "    # 입력 정의\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')  # 정수형 시퀀스 입력\n",
    "\n",
    "    # 임베딩 및 위치 인코딩 추가\n",
    "    dec_inputs = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    x = PositionalEncoding(max_seq_len, d_model)(dec_inputs)\n",
    "\n",
    "    # Look-ahead Mask 생성\n",
    "    seq_len = tf.shape(inputs)[1]\n",
    "    look_ahead_mask = create_look_ahead_mask(seq_len)\n",
    "    look_ahead_mask = look_ahead_mask[tf.newaxis, tf.newaxis, :, :]  # 배치 차원 추가\n",
    "\n",
    "    # Decoder Layer 반복 적용\n",
    "    for _ in range(num_layers):\n",
    "        x = decoder_layer_gpt(units, d_model, num_heads, dropout)([x, look_ahead_mask])\n",
    "\n",
    "    # 출력 레이어: Vocab Size로 확장\n",
    "    outputs = tf.keras.layers.Dense(vocab_size)(x)  # Shape: (batch_size, sequence_length, vocab_size)\n",
    "\n",
    "    # 최종 모델 반환\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c3d6e6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_25\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_1 (TFOpLambd (2,)                 0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_2 (Sli ()                   0           tf.compat.v1.shape_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.ones_1 (TFOpLambda)          (None, None)         0           tf.__operators__.getitem_2[0][0] \n",
      "                                                                 tf.__operators__.getitem_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.linalg.band_part_1 (TFOpLamb (None, None)         0           tf.ones_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 768)    6399744     inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_1 (TFOpLambda) (None, None)         0           tf.linalg.band_part_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "positional_encoding_1 (Position (None, None, 768)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_3 (Sli (1, 1, None, None)   0           tf.math.subtract_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "model_13 (Functional)           (None, None, 768)    7087872     positional_encoding_1[0][0]      \n",
      "                                                                 tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_14 (Functional)           (None, None, 768)    7087872     model_13[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_15 (Functional)           (None, None, 768)    7087872     model_14[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_16 (Functional)           (None, None, 768)    7087872     model_15[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_17 (Functional)           (None, None, 768)    7087872     model_16[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_18 (Functional)           (None, None, 768)    7087872     model_17[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_19 (Functional)           (None, None, 768)    7087872     model_18[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_20 (Functional)           (None, None, 768)    7087872     model_19[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_21 (Functional)           (None, None, 768)    7087872     model_20[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_22 (Functional)           (None, None, 768)    7087872     model_21[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_23 (Functional)           (None, None, 768)    7087872     model_22[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_24 (Functional)           (None, None, 768)    7087872     model_23[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_145 (Dense)               (None, None, 8333)   6408077     model_24[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 97,862,285\n",
      "Trainable params: 97,862,285\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GPT 디코더 모델 생성\n",
    "gpt_model = gpt_decoder(\n",
    "    num_layers=12,      # 디코더 레이어의 개수(6->12)\n",
    "    units=3072,        # Feed Forward 네트워크의 은닉 유닛 크기(2048->3072)\n",
    "    d_model=768,       # 모델의 임베딩 차원 (768)\n",
    "    num_heads=12,       # Multi-Head Attention의 헤드 개수(8->12)\n",
    "    dropout=0.1,       # 드롭아웃 비율\n",
    "    vocab_size=VOCAB_SIZE,  # 단어 집합 크기\n",
    "    max_seq_len=MAX_LENGTH  # 최대 시퀀스 길이\n",
    ")\n",
    "\n",
    "'''\n",
    "    d_model=512,       # 모델의 임베딩 차원 (768)\n",
    "    num_heads=8,       # Multi-Head Attention의 헤드 개수(8->12)\n",
    "    GPU의 한계로 해당 변수로 실험 진행\n",
    "'''\n",
    "\n",
    "\n",
    "# 모델 요약 출력\n",
    "gpt_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e82dd18",
   "metadata": {},
   "source": [
    "Dataset 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4080335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 데이터셋 크기와 배치 크기를 설정\n",
    "BUFFER_SIZE = 10000  # 데이터셋 크기만큼 설정 (적절히 조정 가능)\n",
    "BATCH_SIZE = 32      # 배치 크기 설정\n",
    "\n",
    "# 데이터셋 생성: 입력과 타깃 시퀀스 정의\n",
    "inputs = answers[:, :-1]  # 입력은 타깃의 마지막 토큰을 제외한 부분\n",
    "targets = answers[:, 1:]  # 타깃은 첫 번째 토큰을 제외한 부분\n",
    "\n",
    "# TensorFlow 데이터셋 생성\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {'inputs': inputs},  # 입력 시퀀스\n",
    "    targets               # 타깃 시퀀스\n",
    "))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8944b0",
   "metadata": {},
   "source": [
    "## 4. 학습 데이터 및 모델 컴파일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaa6e54",
   "metadata": {},
   "source": [
    "학습률 스케줄러 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "98de65a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model=768\n",
    "\n",
    "# 커스텀 학습률 스케줄러\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "# 학습률 스케줄러 인스턴스 생성\n",
    "learning_rate = CustomSchedule(d_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e20fe8",
   "metadata": {},
   "source": [
    "옵티마이저 및 손실 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6150249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam 옵티마이저 설정\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9\n",
    ")\n",
    "\n",
    "# 손실 함수 정의\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(y_true, y_pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(y_true, 0))  # 패딩 마스크\n",
    "    loss_ = loss_object(y_true, y_pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7900fc4a",
   "metadata": {},
   "source": [
    "모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a52808dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "\n",
    "# 모델 컴파일\n",
    "gpt_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_function,\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f11269",
   "metadata": {},
   "source": [
    "체크포인트 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3f5a184a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이전 체크포인트 복원이 완료되었습니다!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 체크포인트 디렉토리 설정\n",
    "checkpoint_path = \"./checkpoints/train\"\n",
    "os.makedirs(checkpoint_path, exist_ok=True)\n",
    "\n",
    "# 체크포인트 및 매니저 생성\n",
    "ckpt = tf.train.Checkpoint(transformer=gpt_model, optimizer=optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# 이전 체크포인트 복원\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print('이전 체크포인트 복원이 완료되었습니다!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0249bd",
   "metadata": {},
   "source": [
    "학습 루프 및 히스토리 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7092dc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 1/50 시작\n",
      "1325/1325 [==============================] - 315s 237ms/step - loss: 1.9756 - accuracy: 0.0308\n",
      "체크포인트 저장 완료: ./checkpoints/train/ckpt-4\n",
      "에포크 2/50 시작\n",
      "1325/1325 [==============================] - 314s 237ms/step - loss: 1.9716 - accuracy: 0.0309\n",
      "체크포인트 저장 완료: ./checkpoints/train/ckpt-5\n",
      "에포크 3/50 시작\n",
      "1325/1325 [==============================] - 314s 237ms/step - loss: 1.9696 - accuracy: 0.0310\n",
      "체크포인트 저장 완료: ./checkpoints/train/ckpt-6\n",
      "에포크 4/50 시작\n",
      "1325/1325 [==============================] - 314s 237ms/step - loss: 1.9689 - accuracy: 0.0309\n",
      "체크포인트 저장 완료: ./checkpoints/train/ckpt-7\n",
      "에포크 5/50 시작\n",
      "1325/1325 [==============================] - 314s 237ms/step - loss: 1.9677 - accuracy: 0.0311\n",
      "체크포인트 저장 완료: ./checkpoints/train/ckpt-8\n",
      "에포크 6/50 시작\n",
      "1325/1325 [==============================] - 314s 237ms/step - loss: 1.9668 - accuracy: 0.0312\n",
      "체크포인트 저장 완료: ./checkpoints/train/ckpt-9\n",
      "에포크 7/50 시작\n",
      "1325/1325 [==============================] - 314s 237ms/step - loss: 1.9662 - accuracy: 0.0311\n",
      "체크포인트 저장 완료: ./checkpoints/train/ckpt-10\n",
      "에포크 8/50 시작\n",
      "1325/1325 [==============================] - 314s 237ms/step - loss: 1.9657 - accuracy: 0.0311\n",
      "체크포인트 저장 완료: ./checkpoints/train/ckpt-11\n",
      "에포크 9/50 시작\n",
      "1325/1325 [==============================] - 314s 237ms/step - loss: 1.9655 - accuracy: 0.0311\n",
      "체크포인트 저장 완료: ./checkpoints/train/ckpt-12\n",
      "에포크 10/50 시작\n",
      "1325/1325 [==============================] - 314s 237ms/step - loss: 1.9647 - accuracy: 0.0312\n",
      "체크포인트 저장 완료: ./checkpoints/train/ckpt-13\n",
      "에포크 11/50 시작\n",
      "1325/1325 [==============================] - 314s 237ms/step - loss: 1.9646 - accuracy: 0.0312\n",
      "체크포인트 저장 완료: ./checkpoints/train/ckpt-14\n",
      "에포크 12/50 시작\n",
      "1325/1325 [==============================] - 314s 237ms/step - loss: 1.9642 - accuracy: 0.0313\n",
      "체크포인트 저장 완료: ./checkpoints/train/ckpt-15\n",
      "에포크 13/50 시작\n",
      "1325/1325 [==============================] - 314s 237ms/step - loss: 1.9639 - accuracy: 0.0312\n",
      "체크포인트 저장 완료: ./checkpoints/train/ckpt-16\n",
      "에포크 14/50 시작\n",
      "1325/1325 [==============================] - 315s 237ms/step - loss: 1.9634 - accuracy: 0.0313\n",
      "체크포인트 저장 완료: ./checkpoints/train/ckpt-17\n",
      "에포크 15/50 시작\n",
      "1325/1325 [==============================] - 315s 237ms/step - loss: 1.9643 - accuracy: 0.0313\n",
      "체크포인트 저장 완료: ./checkpoints/train/ckpt-18\n",
      "에포크 16/50 시작\n",
      "1325/1325 [==============================] - 315s 237ms/step - loss: 1.9632 - accuracy: 0.0312\n",
      "체크포인트 저장 완료: ./checkpoints/train/ckpt-19\n",
      "에포크 17/50 시작\n",
      " 105/1325 [=>............................] - ETA: 4:50 - loss: 1.9909 - accuracy: 0.0311"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/3779824506.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# 모델 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     history = gpt_model.fit(\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m  \u001b[0;31m# 에포크별로 수행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \"\"\"\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    510\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 학습 설정\n",
    "EPOCHS = 50  # 학습 에포크 수\n",
    "history_data = {'loss': [], 'accuracy': []}  # 학습 기록 저장용\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"에포크 {epoch + 1}/{EPOCHS} 시작\")\n",
    "    \n",
    "    # 모델 학습\n",
    "    history = gpt_model.fit(\n",
    "        dataset,\n",
    "        epochs=1  # 에포크별로 수행\n",
    "    )\n",
    "    \n",
    "    # 학습 기록 저장\n",
    "    history_data['loss'].append(history.history['loss'][0])\n",
    "    history_data['accuracy'].append(history.history['accuracy'][0])\n",
    "    \n",
    "    # 체크포인트 저장\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print(f\"체크포인트 저장 완료: {ckpt_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a255b412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 1/1 시작\n",
      "1325/1325 [==============================] - 315s 238ms/step - loss: 1.9628 - accuracy: 0.0314\n",
      "체크포인트 저장 완료: ./checkpoints/train/ckpt-20\n"
     ]
    }
   ],
   "source": [
    "# 17에 폭에서 정지 후 결과 확인\n",
    "# 학습 설정\n",
    "EPOCHS = 1  # 학습 에포크 수\n",
    "history_data = {'loss': [], 'accuracy': []}  # 학습 기록 저장용\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"에포크 {epoch + 1}/{EPOCHS} 시작\")\n",
    "    \n",
    "    # 모델 학습\n",
    "    history = gpt_model.fit(\n",
    "        dataset,\n",
    "        epochs=1  # 에포크별로 수행\n",
    "    )\n",
    "    \n",
    "    # 학습 기록 저장\n",
    "    history_data['loss'].append(history.history['loss'][0])\n",
    "    history_data['accuracy'].append(history.history['accuracy'][0])\n",
    "    \n",
    "    # 체크포인트 저장\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print(f\"체크포인트 저장 완료: {ckpt_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6ce9eb",
   "metadata": {},
   "source": [
    "## 5. 학습 데이터 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338ab407",
   "metadata": {},
   "source": [
    "디코더 추론 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7596480e",
   "metadata": {},
   "source": [
    "문장 생성 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1e7184c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#사용하면 i만 출력 됨\n",
    "\n",
    "# def decoder_inference(sentence):\n",
    "#     # 입력 문장을 전처리합니다.\n",
    "#     sentence = preprocess_sentence(sentence)\n",
    "#     sentence = START_TOKEN + tokenizer.encode(sentence) + END_TOKEN\n",
    "#     sentence = tf.expand_dims(sentence, axis=0)  # 배치 차원 추가\n",
    "\n",
    "#     # 초기 입력 설정\n",
    "#     output = tf.expand_dims(START_TOKEN, 0)  # Shape: (1, 1)\n",
    "#     # output 텐서의 데이터 타입 확인 (int32로 가정)\n",
    "#     output = tf.cast(output, dtype=tf.int32)\n",
    "\n",
    "#     for i in range(MAX_LENGTH):\n",
    "#         # 모델에 입력합니다.\n",
    "#         predictions = gpt_model({'inputs': output}, training=False)\n",
    "#         # 마지막 토큰의 확률 분포를 가져옵니다.\n",
    "#         predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
    "#         predicted_id = tf.argmax(predictions, axis=-1, output_type=tf.int32)\n",
    "\n",
    "#         # 예측된 토큰을 출력 시퀀스에 추가합니다.\n",
    "#         output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "#         # END_TOKEN을 예측하면 종료합니다.\n",
    "#         if predicted_id == END_TOKEN[0]:\n",
    "#             break\n",
    "\n",
    "#     return tf.squeeze(output, axis=0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "26e7d1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "    # 입력 문장을 전처리합니다.\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    sentence = START_TOKEN + tokenizer.encode(sentence) + END_TOKEN\n",
    "    sentence = tf.expand_dims(sentence, axis=0)  # 배치 차원 추가\n",
    "\n",
    "    # 초기 입력 설정\n",
    "    output = tf.expand_dims(START_TOKEN, 0)  # Shape: (1, 1)\n",
    "    output = tf.cast(output, dtype=tf.int32)\n",
    "\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # 모델에 입력합니다.\n",
    "        predictions = gpt_model({'inputs': output}, training=False)\n",
    "        predictions = predictions[:, -1, :]  # (batch_size, vocab_size)\n",
    "\n",
    "        # 온도 적용\n",
    "        temperature = 0.7  #매우보수적으로 설정, 0.1일 때 i만 출력\n",
    "        predictions = predictions / temperature\n",
    "\n",
    "        # 확률 분포에서 다음 토큰 샘플링\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)  # Shape: (batch_size, 1)\n",
    "        predicted_id = tf.cast(predicted_id, tf.int32)  # Shape: (1, 1)\n",
    "\n",
    "        # 예측된 토큰을 출력 시퀀스에 추가합니다.\n",
    "        output = tf.concat([output, predicted_id], axis=-1)  # output: (1, sequence_length)\n",
    "\n",
    "        # END_TOKEN을 예측하면 종료합니다.\n",
    "        if predicted_id.numpy()[0][0] == END_TOKEN[0]:\n",
    "            break\n",
    "\n",
    "    return tf.squeeze(output, axis=0).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5cc538ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "    prediction = decoder_inference(sentence)\n",
    "    # 특수 토큰 제거\n",
    "    prediction = prediction[1:]  # START_TOKEN 제거\n",
    "    if END_TOKEN[0] in prediction:\n",
    "        prediction = prediction[:np.where(prediction == END_TOKEN[0])[0][0]]\n",
    "\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [i for i in prediction if i < tokenizer.vocab_size]\n",
    "    )\n",
    "\n",
    "    print('Input:', sentence)\n",
    "    print('Output:', predicted_sentence)\n",
    "\n",
    "    return predicted_sentence\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2211f983",
   "metadata": {},
   "source": [
    "모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0664de7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Where have you been?\n",
      "Output: iyou he noi you yeahnoohcan the we i what i hei i ii i yesi yeahi iiyesiti she are not i you you noohyou we \n",
      "Input: It's a trap\n",
      "Output: forget what noi what welli i inononowelli i i why i do i i maybe what sheyou you yeahwhati the you i whatthat iti you i it no\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'forget what noi what welli i inononowelli i i why i do i i maybe what sheyou you yeahwhati the you i whatthat iti you i it no'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예시 문장으로 챗봇의 응답을 확인합니다.\n",
    "sentence_generation('Where have you been?')\n",
    "sentence_generation(\"It's a trap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c701c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
