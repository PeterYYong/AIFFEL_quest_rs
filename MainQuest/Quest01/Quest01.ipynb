{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36f49a30",
   "metadata": {},
   "source": [
    "## 1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c03dd530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdca8ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cornell 대화 데이터 로드 및 전처리\n",
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'cornell_movie_dialogs.zip',\n",
    "    origin='http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip',\n",
    "    extract=True\n",
    ")\n",
    "path_to_dataset = path_to_zip.replace('cornell_movie_dialogs.zip', 'cornell movie-dialogs corpus/')\n",
    "path_to_movie_lines = path_to_dataset + 'movie_lines.txt'\n",
    "path_to_movie_conversations = path_to_dataset + 'movie_conversations.txt'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "21f790d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "    \"\"\"문장을 소문자로 변환하고 불필요한 문자를 제거\"\"\"\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
    "    return sentence.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d41e1e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대화 데이터를 로드하고 질문/답변 쌍 생성\n",
    "def load_conversations():\n",
    "    \"\"\"Cornell 대화 데이터를 로드하여 질문/답변 쌍 생성\"\"\"\n",
    "    id2line = {}\n",
    "    with open(path_to_movie_lines, errors='ignore') as file:\n",
    "        lines = file.readlines()\n",
    "    for line in lines:\n",
    "        parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "        id2line[parts[0]] = parts[4]\n",
    "\n",
    "    inputs, outputs = [], []\n",
    "    with open(path_to_movie_conversations, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "        conversation = [line[1:-1] for line in parts[3][1:-1].split(', ')]\n",
    "\n",
    "        for i in range(len(conversation) - 1):\n",
    "            inputs.append(preprocess_sentence(id2line[conversation[i]]))\n",
    "            outputs.append(preprocess_sentence(id2line[conversation[i + 1]]))\n",
    "            if len(inputs) >= 50000:  # 최대 샘플 크기 설정\n",
    "                return inputs, outputs\n",
    "    return inputs, outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0d264562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "questions, answers = load_conversations()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a6583ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGPT-1에서는 Byte Pair Encoding (BPE)를 사용하여 서브워드 단위의 토크나이징을 수행하였으나,\\n이번 코드에서는 TensorFlow Datasets의 SubwordTextEncoder를 사용\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토크나이저 설정\n",
    "\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers, target_vocab_size=2**13\n",
    ")\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "\n",
    "'''\n",
    "GPT-1에서는 Byte Pair Encoding (BPE)를 사용하여 서브워드 단위의 토크나이징을 수행하였으나,\n",
    "이번 코드에서는 TensorFlow Datasets의 SubwordTextEncoder를 사용\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06b9ac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 및 패딩 처리\n",
    "\n",
    "\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    \"\"\"\n",
    "    문자열 데이터를 토큰화하고 패딩 처리.\n",
    "    inputs와 outputs가 이미 정수화된 경우, 추가 처리를 하지 않습니다.\n",
    "    \"\"\"\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "    \n",
    "\n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        # 데이터가 문자열인지 확인\n",
    "        if isinstance(sentence1, str):\n",
    "            sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "            sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "        # MAX_LENGTH 이하인 문장만 처리\n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "\n",
    "    # 패딩 처리\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "    return tokenized_inputs, tokenized_outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a69fddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 및 패딩 처리\n",
    "MAX_LENGTH = 768  # 데이터와 모델에 맞게 조정 가능\n",
    "questions, answers = tokenize_and_filter(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe2c8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ada87d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877d09a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95f60ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd93f63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c086dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b1b3565",
   "metadata": {},
   "source": [
    "## 2. Positional Encoding 및 Attention Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0739c1a3",
   "metadata": {},
   "source": [
    "Positional Encoding 클래스\n",
    "\n",
    "위치 정보를 벡터화하여 시퀀스 데이터에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87d2d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        \"\"\"\n",
    "        Positional Encoding을 초기화.\n",
    "        - position: 최대 위치의 개수 (시퀀스 길이)\n",
    "        - d_model: 임베딩 차원\n",
    "        \"\"\"\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        \"\"\"\n",
    "        각 위치와 임베딩 차원에 대한 각도를 계산.\n",
    "        - position: 위치 값\n",
    "        - i: 차원 인덱스\n",
    "        - d_model: 모델 차원\n",
    "        \"\"\"\n",
    "        return position / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        \"\"\"\n",
    "        Sine과 Cosine을 사용하여 위치 인코딩 계산.\n",
    "        - position: 시퀀스 길이\n",
    "        - d_model: 임베딩 차원\n",
    "        \"\"\"\n",
    "        angle_rads = self.get_angles(\n",
    "            np.arange(position)[:, np.newaxis],  # 위치 (행렬 형태)\n",
    "            np.arange(d_model)[np.newaxis, :],  # 임베딩 차원\n",
    "            d_model\n",
    "        )\n",
    "        # 짝수 인덱스에 Sine 적용\n",
    "        sines = np.sin(angle_rads[:, 0::2])\n",
    "        # 홀수 인덱스에 Cosine 적용\n",
    "        cosines = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        # Sine과 Cosine 결합\n",
    "        pos_encoding = np.concatenate([sines, cosines], axis=-1)\n",
    "        pos_encoding = pos_encoding[np.newaxis, ...]  # 배치 차원 추가\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        입력 텐서에 위치 인코딩 추가.\n",
    "        - inputs: 입력 텐서\n",
    "        \"\"\"\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bc1cd7",
   "metadata": {},
   "source": [
    "Scaled Dot-Product Attention\n",
    "\n",
    "Query와 Key의 유사도를 계산하고, Value에 가중치를 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07151507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    \"\"\"\n",
    "    Scaled Dot-Product Attention 계산.\n",
    "    - query: Query 행렬\n",
    "    - key: Key 행렬\n",
    "    - value: Value 행렬\n",
    "    - mask: 패딩 마스크 (필요 시 적용)\n",
    "\n",
    "    반환값:\n",
    "    - output: 가중치가 적용된 Value 행렬\n",
    "    \"\"\"\n",
    "    # Query와 Key의 내적 계산\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # Key의 차원으로 스케일링\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # 마스크가 있다면 -∞ 값을 추가하여 무시\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # Softmax로 Attention 가중치 계산\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    # Attention 가중치를 Value에 곱함\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d81b89",
   "metadata": {},
   "source": [
    "Multi-Head Attention 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4604fcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        \"\"\"\n",
    "        Multi-Head Attention 초기화.\n",
    "        - d_model: 모델의 전체 차원\n",
    "        - num_heads: 헤드의 개수\n",
    "        \"\"\"\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # d_model이 num_heads로 나누어떨어지는지 확인\n",
    "        assert d_model % num_heads == 0\n",
    "\n",
    "        # 각 헤드의 차원\n",
    "        self.depth = d_model // num_heads\n",
    "\n",
    "        # Query, Key, Value를 위한 Dense 레이어\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        # 최종 출력 Dense 레이어\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        \"\"\"\n",
    "        입력 텐서를 다중 헤드로 분리.\n",
    "        - inputs: Dense 레이어 출력\n",
    "        - batch_size: 배치 크기\n",
    "        \"\"\"\n",
    "        # (batch_size, seq_len, d_model) -> (batch_size, seq_len, num_heads, depth)\n",
    "        inputs = tf.reshape(inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        # 헤드 축과 시퀀스 축을 교환\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Multi-Head Attention 계산.\n",
    "        - inputs: Query, Key, Value, Mask를 포함한 딕셔너리\n",
    "        \"\"\"\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # Query, Key, Value 생성 및 다중 헤드로 분리\n",
    "        query = self.split_heads(self.query_dense(query), batch_size)\n",
    "        key = self.split_heads(self.key_dense(key), batch_size)\n",
    "        value = self.split_heads(self.value_dense(value), batch_size)\n",
    "\n",
    "        # Scaled Dot-Product Attention 수행\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        # 헤드 통합\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "\n",
    "        # 최종 Dense 레이어 통과\n",
    "        return self.dense(concat_attention)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16c58db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9947e002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6780b08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbedae44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fc6cbfc",
   "metadata": {},
   "source": [
    "## 3. GPT 모델 구현\n",
    "\n",
    "GPT 모델은 Transformer 기반으로 하되, 인코더를 제거하고 디코더만 사용하여 생성 모델로 동작하도록 수정되었습니다. \n",
    "\n",
    "\n",
    "주요 변경 사항:\n",
    "\n",
    "- 인코더 제거: Transformer의 인코더-디코더 구조 중 인코더를 제거하고 디코더만 사용.\n",
    "- Look-Ahead Mask: GPT는 Causal Language Modeling을 위해 Look-Ahead Mask를 적용.\n",
    "- 위치 정보 추가: 입력 데이터에 위치 정보를 추가하는 PositionalEncoding 레이어 구현.\n",
    "- 학습 데이터 전처리: 디코더 입력과 출력 데이터를 시프트하여 구성."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44458a47",
   "metadata": {},
   "source": [
    "GPT Decoder Layer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eeb88a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT 모델 디코더 레이어 정의\n",
    "def decoder_layer_gpt(units, d_model, num_heads, dropout):\n",
    "    \"\"\"\n",
    "    GPT의 Decoder Layer를 정의.\n",
    "    - units: Feed Forward 네트워크의 은닉 유닛 크기\n",
    "    - d_model: 임베딩 차원\n",
    "    - num_heads: Multi-Head Attention의 헤드 개수\n",
    "    - dropout: 드롭아웃 비율\n",
    "    \"\"\"\n",
    "    # 입력 텐서 정의\n",
    "    inputs = tf.keras.Input(shape=(None, d_model))  # 입력 임베딩\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None))  # Look-ahead 마스크\n",
    "\n",
    "    # Multi-Head Attention\n",
    "    attention = MultiHeadAttention(d_model, num_heads)(\n",
    "        {'query': inputs, 'key': inputs, 'value': inputs, 'mask': look_ahead_mask}\n",
    "    )\n",
    "    # 잔차 연결과 Layer Normalization\n",
    "    attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + inputs)\n",
    "\n",
    "    # Feed Forward 네트워크\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "\n",
    "    # 잔차 연결과 Layer Normalization\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention)\n",
    "\n",
    "    # 모델 반환\n",
    "    return tf.keras.Model(inputs=[inputs, look_ahead_mask], outputs=outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d91aaf",
   "metadata": {},
   "source": [
    "Look-Ahead Mask 생성 함수\n",
    "\n",
    "Look-ahead Mask는 Transformer에서 미래 정보를 차단하는 데 사용됩니다. 상삼각 행렬로 구성된 마스크는 디코더가 현재 토큰 이후의 정보를 보지 못하게 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34e96ace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(seq_len):\n",
    "    \"\"\"\n",
    "    Look-ahead 마스크 생성.\n",
    "    - seq_len: 시퀀스 길이\n",
    "    반환값:\n",
    "    - 상삼각 행렬로 이루어진 마스크 텐서\n",
    "    \"\"\"\n",
    "    return 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26af1b0",
   "metadata": {},
   "source": [
    "GPT 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a711d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_decoder(num_layers, units, d_model, num_heads, dropout, vocab_size, max_seq_len):\n",
    "    \"\"\"\n",
    "    GPT Decoder를 구성.\n",
    "    - num_layers: Decoder Layer의 개수\n",
    "    - units: Feed Forward 네트워크의 은닉 유닛 크기\n",
    "    - d_model: 임베딩 차원\n",
    "    - num_heads: Multi-Head Attention의 헤드 개수\n",
    "    - dropout: 드롭아웃 비율\n",
    "    - vocab_size: 단어 집합 크기\n",
    "    - max_seq_len: 최대 시퀀스 길이\n",
    "    \"\"\"\n",
    "    # 입력 정의\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')  # 정수형 시퀀스 입력\n",
    "\n",
    "    # 임베딩 및 위치 인코딩 추가\n",
    "    dec_inputs = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    x = PositionalEncoding(max_seq_len, d_model)(dec_inputs)\n",
    "\n",
    "    # Look-ahead Mask 생성\n",
    "    seq_len = tf.shape(inputs)[1]\n",
    "    look_ahead_mask = create_look_ahead_mask(seq_len)\n",
    "    look_ahead_mask = look_ahead_mask[tf.newaxis, tf.newaxis, :, :]  # 배치 차원 추가\n",
    "\n",
    "    # Decoder Layer 반복 적용\n",
    "    for _ in range(num_layers):\n",
    "        x = decoder_layer_gpt(units, d_model, num_heads, dropout)([x, look_ahead_mask])\n",
    "\n",
    "    # 출력 레이어: Vocab Size로 확장\n",
    "    outputs = tf.keras.layers.Dense(vocab_size)(x)  # Shape: (batch_size, sequence_length, vocab_size)\n",
    "\n",
    "    # 최종 모델 반환\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05893558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_25\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_1 (TFOpLambd (2,)                 0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_2 (Sli ()                   0           tf.compat.v1.shape_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.ones_1 (TFOpLambda)          (None, None)         0           tf.__operators__.getitem_2[0][0] \n",
      "                                                                 tf.__operators__.getitem_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.linalg.band_part_1 (TFOpLamb (None, None)         0           tf.ones_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 768)    6399744     inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_1 (TFOpLambda) (None, None)         0           tf.linalg.band_part_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "positional_encoding_1 (Position (None, None, 768)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_3 (Sli (1, 1, None, None)   0           tf.math.subtract_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "model_13 (Functional)           (None, None, 768)    7087872     positional_encoding_1[0][0]      \n",
      "                                                                 tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_14 (Functional)           (None, None, 768)    7087872     model_13[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_15 (Functional)           (None, None, 768)    7087872     model_14[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_16 (Functional)           (None, None, 768)    7087872     model_15[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_17 (Functional)           (None, None, 768)    7087872     model_16[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_18 (Functional)           (None, None, 768)    7087872     model_17[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_19 (Functional)           (None, None, 768)    7087872     model_18[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_20 (Functional)           (None, None, 768)    7087872     model_19[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_21 (Functional)           (None, None, 768)    7087872     model_20[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_22 (Functional)           (None, None, 768)    7087872     model_21[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_23 (Functional)           (None, None, 768)    7087872     model_22[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_24 (Functional)           (None, None, 768)    7087872     model_23[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_145 (Dense)               (None, None, 8333)   6408077     model_24[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 97,862,285\n",
      "Trainable params: 97,862,285\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GPT 디코더 모델 생성\n",
    "gpt_model = gpt_decoder(\n",
    "    num_layers=12,      # 디코더 레이어의 개수(6->12)\n",
    "    units=3072,        # Feed Forward 네트워크의 은닉 유닛 크기(2048->3072)\n",
    "    d_model=768,       # 모델의 임베딩 차원 (512->768)\n",
    "    num_heads=12,       # Multi-Head Attention의 헤드 개수(8->12)\n",
    "    dropout=0.1,       # 드롭아웃 비율\n",
    "    vocab_size=VOCAB_SIZE,  # 단어 집합 크기\n",
    "    max_seq_len=MAX_LENGTH  # 최대 시퀀스 길이\n",
    ")\n",
    "\n",
    "# 모델 요약 출력\n",
    "gpt_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167ced14",
   "metadata": {},
   "source": [
    "Dataset 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3718050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 데이터셋 크기와 배치 크기를 설정\n",
    "BUFFER_SIZE = 10000  # 데이터셋 크기만큼 설정 (적절히 조정 가능)\n",
    "BATCH_SIZE = 64      # 배치 크기 설정\n",
    "\n",
    "# 데이터셋 생성: 입력과 타깃 시퀀스 정의\n",
    "inputs = answers[:, :-1]  # 입력은 타깃의 마지막 토큰을 제외한 부분\n",
    "targets = answers[:, 1:]  # 타깃은 첫 번째 토큰을 제외한 부분\n",
    "\n",
    "# TensorFlow 데이터셋 생성\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {'inputs': inputs},  # 입력 시퀀스\n",
    "    targets               # 타깃 시퀀스\n",
    "))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab954f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df4aeef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2eab2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96534025",
   "metadata": {},
   "source": [
    "## 4. 학습 데이터 및 모델 컴파일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fb423c",
   "metadata": {},
   "source": [
    "학습률 스케줄러 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fd03b946",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 커스텀 학습률 스케줄러\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "# 학습률 스케줄러 인스턴스 생성\n",
    "learning_rate = CustomSchedule(d_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c46649",
   "metadata": {},
   "source": [
    "옵티마이저 및 손실 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cafd3f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam 옵티마이저 설정\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9\n",
    ")\n",
    "\n",
    "# 손실 함수 정의\n",
    "def loss_function(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    손실 함수 계산.\n",
    "    - y_true: 실제 값\n",
    "    - y_pred: 예측 값\n",
    "    \"\"\"\n",
    "    mask = tf.math.logical_not(tf.math.equal(y_true, 0))  # 패딩 마스크 생성\n",
    "    loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)  # 마스크 형변환\n",
    "    loss *= mask  # 마스크 적용\n",
    "    return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b403ed",
   "metadata": {},
   "source": [
    "모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dcb19695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "\n",
    "# 모델 컴파일\n",
    "gpt_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_function,\n",
    "    metrics=[SparseCategoricalAccuracy(name='accuracy')]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7b2a14",
   "metadata": {},
   "source": [
    "체크포인트 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d2b178b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shapes (8333, 768) and (8333, 512) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_717/2953797344.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 이전 체크포인트 복원\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mckpt_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'이전 체크포인트 복원이 완료되었습니다!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, save_path, options)\u001b[0m\n\u001b[1;32m   2333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2334\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2335\u001b[0;31m       \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2336\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2337\u001b[0m       raise errors_impl.NotFoundError(\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, save_path, options)\u001b[0m\n\u001b[1;32m   2218\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2219\u001b[0m     \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcheckpoint_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpointOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2220\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2221\u001b[0m     _checkpoint_read_durations.get_cell(\"V2\").add(\n\u001b[1;32m   2222\u001b[0m         _get_duration_microseconds(start_time, time.time()))\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, save_path, options)\u001b[0m\n\u001b[1;32m   1380\u001b[0m         \u001b[0mgraph_view\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_view\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m         options=options)\n\u001b[0;32m-> 1382\u001b[0;31m     base.CheckpointPosition(\n\u001b[0m\u001b[1;32m   1383\u001b[0m         checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root)\n\u001b[1;32m   1384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, trackable)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;31m# This object's correspondence with a checkpointed object is new, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;31m# process deferred restorations for it and its dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mrestore_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_from_checkpoint_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestore_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_restore_from_checkpoint_position\u001b[0;34m(self, checkpoint_position)\u001b[0m\n\u001b[1;32m    978\u001b[0m       \u001b[0mpython_saveables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_python_saveables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m     restore_ops.extend(\n\u001b[0;32m--> 980\u001b[0;31m         current_position.checkpoint.restore_saveables(\n\u001b[0m\u001b[1;32m    981\u001b[0m             tensor_saveables, python_saveables))\n\u001b[1;32m    982\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36mrestore_saveables\u001b[0;34m(self, tensor_saveables, python_saveables)\u001b[0m\n\u001b[1;32m    349\u001b[0m             (\"Saveable keys changed when validating. Got back %s, was \"\n\u001b[1;32m    350\u001b[0m              \"expecting %s\") % (tensor_saveables.keys(), validated_names))\n\u001b[0;32m--> 351\u001b[0;31m       new_restore_ops = functional_saver.MultiDeviceSaver(\n\u001b[0m\u001b[1;32m    352\u001b[0m           validated_saveables).restore(self.save_path_tensor, self.options)\n\u001b[1;32m    353\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m    337\u001b[0m       \u001b[0mrestore_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_function_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m       \u001b[0mrestore_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_restore_callbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36mrestore_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    321\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_single_device_savers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m           \u001b[0mrestore_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m    113\u001b[0m     for saveable, restored_tensors in zip(self._saveable_objects,\n\u001b[1;32m    114\u001b[0m                                           structured_restored_tensors):\n\u001b[0;32m--> 115\u001b[0;31m       restore_ops[saveable.name] = saveable.restore(\n\u001b[0m\u001b[1;32m    116\u001b[0m           restored_tensors, restored_shapes=None)\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/training/saving/saveable_object_util.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, restored_tensors, restored_shapes)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_var_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m       \u001b[0mrestored_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestored_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m       return resource_variable_ops.shape_safe_assign_variable_handle(\n\u001b[0m\u001b[1;32m    132\u001b[0m           self.handle_op, self._var_shape, restored_tensor)\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mshape_safe_assign_variable_handle\u001b[0;34m(handle, shape, value, name)\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0m_handle_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0mvalue_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m   \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m   return gen_resource_variable_ops.assign_variable_op(\n\u001b[1;32m    311\u001b[0m       handle, value_tensor, name=name)\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \"\"\"\n\u001b[1;32m   1160\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (8333, 768) and (8333, 512) are incompatible"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 체크포인트 디렉토리 설정\n",
    "checkpoint_path = \"./checkpoints/train\"\n",
    "os.makedirs(checkpoint_path, exist_ok=True)\n",
    "\n",
    "# 체크포인트 및 매니저 생성\n",
    "ckpt = tf.train.Checkpoint(transformer=gpt_model, optimizer=optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# 이전 체크포인트 복원\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print('이전 체크포인트 복원이 완료되었습니다!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b945da0b",
   "metadata": {},
   "source": [
    "학습 루프 및 히스토리 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f2ee9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 1/1 시작\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:791 train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:522 minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:659 apply_gradients\n        return self._distributed_apply(strategy, grads_and_vars, name,\n    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:706 _distributed_apply\n        update_op = distribution.extended.update(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2594 update\n        return self._replica_ctx_update(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2473 _replica_ctx_update\n        return replica_context.merge_call(merge_fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3064 merge_call\n        return self._merge_call(merge_fn, args, kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3071 _merge_call\n        return merge_fn(self._strategy, *args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2471 merge_fn  **\n        return self.update(var, fn, merged_args, merged_kwargs, group=group)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2592 update\n        return self._update(var, fn, args, kwargs, group)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3646 _update\n        return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3652 _update_non_slot\n        result = fn(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:684 apply_grad_to_update_var  **\n        return self._resource_apply_sparse_duplicate_indices(\n    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:1268 _resource_apply_sparse_duplicate_indices\n        return self._resource_apply_sparse(summed_grad, handle, unique_indices,\n    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:204 _resource_apply_sparse\n        m_t = self._resource_scatter_add(m, indices, m_scaled_g_values)\n    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:1294 _resource_scatter_add\n        tf.raw_ops.ResourceScatterAdd(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/tf_export.py:404 wrapper\n        return f(**kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py:719 resource_scatter_add\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:599 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3561 _create_op_internal\n        ret = Operation(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2041 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimension 1 in both shapes must be equal, but are 768 and 512. Shapes are [?,768] and [?,512]. for '{{node Adam/Adam/update/ResourceScatterAdd}} = ResourceScatterAdd[Tindices=DT_INT32, dtype=DT_FLOAT](Adam/Adam/update/ReadVariableOp/resource, Adam/Adam/update/Unique, Adam/Adam/update/mul, ^Adam/Adam/update/AssignVariableOp)' with input shapes: [], [?], [?,768].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_717/3025339217.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# 모델 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     history = gpt_model.fit(\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m  \u001b[0;31m# 에포크별로 수행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 759\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    760\u001b[0m             *args, **kwds))\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3298\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /opt/conda/lib/python3.9/site-packages/keras/engine/training.py:791 train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:522 minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:659 apply_gradients\n        return self._distributed_apply(strategy, grads_and_vars, name,\n    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:706 _distributed_apply\n        update_op = distribution.extended.update(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2594 update\n        return self._replica_ctx_update(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2473 _replica_ctx_update\n        return replica_context.merge_call(merge_fn, args=args, kwargs=kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3064 merge_call\n        return self._merge_call(merge_fn, args, kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3071 _merge_call\n        return merge_fn(self._strategy, *args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2471 merge_fn  **\n        return self.update(var, fn, merged_args, merged_kwargs, group=group)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2592 update\n        return self._update(var, fn, args, kwargs, group)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3646 _update\n        return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3652 _update_non_slot\n        result = fn(*args, **kwargs)\n    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:684 apply_grad_to_update_var  **\n        return self._resource_apply_sparse_duplicate_indices(\n    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:1268 _resource_apply_sparse_duplicate_indices\n        return self._resource_apply_sparse(summed_grad, handle, unique_indices,\n    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:204 _resource_apply_sparse\n        m_t = self._resource_scatter_add(m, indices, m_scaled_g_values)\n    /opt/conda/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:1294 _resource_scatter_add\n        tf.raw_ops.ResourceScatterAdd(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/tf_export.py:404 wrapper\n        return f(**kwargs)\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py:719 resource_scatter_add\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:599 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3561 _create_op_internal\n        ret = Operation(\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2041 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimension 1 in both shapes must be equal, but are 768 and 512. Shapes are [?,768] and [?,512]. for '{{node Adam/Adam/update/ResourceScatterAdd}} = ResourceScatterAdd[Tindices=DT_INT32, dtype=DT_FLOAT](Adam/Adam/update/ReadVariableOp/resource, Adam/Adam/update/Unique, Adam/Adam/update/mul, ^Adam/Adam/update/AssignVariableOp)' with input shapes: [], [?], [?,768].\n"
     ]
    }
   ],
   "source": [
    "# 학습 설정\n",
    "EPOCHS = 1  # 학습 에포크 수\n",
    "history_data = {'loss': [], 'accuracy': []}  # 학습 기록 저장용\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"에포크 {epoch + 1}/{EPOCHS} 시작\")\n",
    "    \n",
    "    # 모델 학습\n",
    "    history = gpt_model.fit(\n",
    "        dataset,\n",
    "        epochs=1  # 에포크별로 수행\n",
    "    )\n",
    "    \n",
    "    # 학습 기록 저장\n",
    "    history_data['loss'].append(history.history['loss'][0])\n",
    "    history_data['accuracy'].append(history.history['accuracy'][0])\n",
    "    \n",
    "    # 체크포인트 저장\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print(f\"체크포인트 저장 완료: {ckpt_save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb4b882",
   "metadata": {},
   "source": [
    "## 5. 학습 데이터 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7149cc70",
   "metadata": {},
   "source": [
    "디코더 추론 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbfeef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "    \"\"\"\n",
    "    입력 문장을 GPT 모델을 사용해 정수 시퀀스로 변환.\n",
    "    - sentence: 입력 문장 (문자열)\n",
    "    반환값: 예측된 정수 시퀀스 (NumPy 배열)\n",
    "    \"\"\"\n",
    "    # 입력 문장 전처리\n",
    "    sentence = preprocess_sentence(sentence)  # 불필요한 문자 제거 및 소문자화\n",
    "    sentence = START_TOKEN + tokenizer.encode(sentence) + END_TOKEN  # 토큰화 및 시작/끝 토큰 추가\n",
    "    sentence = tf.expand_dims(sentence, axis=0)  # 배치 차원 추가\n",
    "\n",
    "    # 초기 출력 설정\n",
    "    output = tf.expand_dims(START_TOKEN, 0)  # 시작 토큰 추가, Shape: (1, 1)\n",
    "    output = tf.cast(output, dtype=tf.int32)  # 데이터 타입 지정\n",
    "\n",
    "    # MAX_LENGTH 만큼 반복하여 시퀀스를 생성\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # GPT 모델에 입력\n",
    "        predictions = gpt_model({'inputs': output}, training=False)\n",
    "\n",
    "        # 마지막 토큰의 확률 분포 추출\n",
    "        predictions = predictions[:, -1:, :]  # Shape: (batch_size, 1, vocab_size)\n",
    "\n",
    "        # 가장 높은 확률을 가진 토큰의 ID 선택\n",
    "        predicted_id = tf.argmax(predictions, axis=-1, output_type=tf.int32)\n",
    "\n",
    "        # 예측된 토큰을 출력 시퀀스에 추가\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "        # END_TOKEN을 예측하면 루프 종료\n",
    "        if predicted_id == END_TOKEN[0]:\n",
    "            break\n",
    "\n",
    "    # 최종 시퀀스 반환 (배치 차원 제거)\n",
    "    return tf.squeeze(output, axis=0).numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9af7ab",
   "metadata": {},
   "source": [
    "문장 생성 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b98bea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "    \"\"\"\n",
    "    입력 문장에 대한 GPT 디코더의 응답 생성.\n",
    "    - sentence: 입력 문장 (문자열)\n",
    "    반환값: 생성된 응답 문장 (문자열)\n",
    "    \"\"\"\n",
    "    # 디코더를 사용해 정수 시퀀스 예측\n",
    "    prediction = decoder_inference(sentence)\n",
    "\n",
    "    # 정수 시퀀스를 텍스트로 디코딩\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [i for i in prediction if i < tokenizer.vocab_size]  # 단어 집합 크기 이하의 토큰만 디코딩\n",
    "    )\n",
    "\n",
    "    # 입력 및 출력 문장 출력\n",
    "    print('Input:', sentence)\n",
    "    print('Output:', predicted_sentence)\n",
    "\n",
    "    return predicted_sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2499a78b",
   "metadata": {},
   "source": [
    "모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141f549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시 문장으로 챗봇 응답 확인\n",
    "sentence_generation('Where have you been?')\n",
    "sentence_generation(\"It's a trap\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a2ca4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c7691a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c4e9f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bf3116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d285b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806d7547",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd9f311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10436314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467dc728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7703393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb65995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a63deb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1e18c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804bf985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bfb8a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75914e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee48c588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f189dd0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b1fbf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcddeee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20372093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd73e8dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afe960f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f5e59f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24868fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec041ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40705867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6514695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7040b66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f9ea16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59765163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561a631a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d48b4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7595e843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3cceb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
