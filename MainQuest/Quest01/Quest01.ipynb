{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b040dca4",
   "metadata": {},
   "source": [
    "## 1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf5ab282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b8ac283",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cornell 대화 데이터 로드 및 전처리\n",
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'cornell_movie_dialogs.zip',\n",
    "    origin='http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip',\n",
    "    extract=True\n",
    ")\n",
    "path_to_dataset = path_to_zip.replace('cornell_movie_dialogs.zip', 'cornell movie-dialogs corpus/')\n",
    "path_to_movie_lines = path_to_dataset + 'movie_lines.txt'\n",
    "path_to_movie_conversations = path_to_dataset + 'movie_conversations.txt'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f1a3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "    \"\"\"문장을 소문자로 변환하고 불필요한 문자를 제거\"\"\"\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
    "    return sentence.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e44fc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대화 데이터를 로드하고 질문/답변 쌍 생성\n",
    "def load_conversations():\n",
    "    \"\"\"Cornell 대화 데이터를 로드하여 질문/답변 쌍 생성\"\"\"\n",
    "    id2line = {}\n",
    "    with open(path_to_movie_lines, errors='ignore') as file:\n",
    "        lines = file.readlines()\n",
    "    for line in lines:\n",
    "        parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "        id2line[parts[0]] = parts[4]\n",
    "\n",
    "    inputs, outputs = [], []\n",
    "    with open(path_to_movie_conversations, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "        conversation = [line[1:-1] for line in parts[3][1:-1].split(', ')]\n",
    "\n",
    "        for i in range(len(conversation) - 1):\n",
    "            inputs.append(preprocess_sentence(id2line[conversation[i]]))\n",
    "            outputs.append(preprocess_sentence(id2line[conversation[i + 1]]))\n",
    "            if len(inputs) >= 50000:  # 최대 샘플 크기 설정\n",
    "                return inputs, outputs\n",
    "    return inputs, outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f9b7e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "questions, answers = load_conversations()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec61c528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGPT-1에서는 Byte Pair Encoding (BPE)를 사용하여 서브워드 단위의 토크나이징을 수행하였으나,\\n이번 코드에서는 TensorFlow Datasets의 SubwordTextEncoder를 사용\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토크나이저 설정\n",
    "\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers, target_vocab_size=2**13\n",
    ")\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "\n",
    "'''\n",
    "GPT-1에서는 Byte Pair Encoding (BPE)를 사용하여 서브워드 단위의 토크나이징을 수행하였으나,\n",
    "이번 코드에서는 TensorFlow Datasets의 SubwordTextEncoder를 사용\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7a5c0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 및 패딩 처리\n",
    "MAX_LENGTH=40\n",
    "# 문장 토큰화 및 패딩 처리\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    \"\"\"토큰화 및 패딩 처리\"\"\"\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "    # Check if inputs are raw strings\n",
    "    if isinstance(inputs[0], str):\n",
    "        for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "            # 정수 인코딩\n",
    "            sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "            sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "            # 최대 길이 초과 샘플 필터링\n",
    "            if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "                tokenized_inputs.append(sentence1)\n",
    "                tokenized_outputs.append(sentence2)\n",
    "    else:\n",
    "        # If inputs are already tokenized\n",
    "        tokenized_inputs = inputs\n",
    "        tokenized_outputs = outputs\n",
    "\n",
    "    # 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding='post'\n",
    "    )\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LENGTH, padding='post'\n",
    "    )\n",
    "\n",
    "    return tokenized_inputs, tokenized_outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04fd0264",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 토큰화 및 패딩 처리 호출\n",
    "questions, answers = tokenize_and_filter(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305521d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdbb8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52088f82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0b6730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43500cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effdf2dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a10a702d",
   "metadata": {},
   "source": [
    "## 2. Positional Encoding 및 Attention Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e12ae74",
   "metadata": {},
   "source": [
    "Positional Encoding 클래스\n",
    "\n",
    "위치 정보를 벡터화하여 시퀀스 데이터에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a30eb526",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        \"\"\"\n",
    "        Positional Encoding을 초기화.\n",
    "        - position: 최대 위치의 개수 (시퀀스 길이)\n",
    "        - d_model: 임베딩 차원\n",
    "        \"\"\"\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        \"\"\"\n",
    "        각 위치와 임베딩 차원에 대한 각도를 계산.\n",
    "        - position: 위치 값\n",
    "        - i: 차원 인덱스\n",
    "        - d_model: 모델 차원\n",
    "        \"\"\"\n",
    "        return position / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        \"\"\"\n",
    "        Sine과 Cosine을 사용하여 위치 인코딩 계산.\n",
    "        - position: 시퀀스 길이\n",
    "        - d_model: 임베딩 차원\n",
    "        \"\"\"\n",
    "        angle_rads = self.get_angles(\n",
    "            np.arange(position)[:, np.newaxis],  # 위치 (행렬 형태)\n",
    "            np.arange(d_model)[np.newaxis, :],  # 임베딩 차원\n",
    "            d_model\n",
    "        )\n",
    "        # 짝수 인덱스에 Sine 적용\n",
    "        sines = np.sin(angle_rads[:, 0::2])\n",
    "        # 홀수 인덱스에 Cosine 적용\n",
    "        cosines = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        # Sine과 Cosine 결합\n",
    "        pos_encoding = np.concatenate([sines, cosines], axis=-1)\n",
    "        pos_encoding = pos_encoding[np.newaxis, ...]  # 배치 차원 추가\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        입력 텐서에 위치 인코딩 추가.\n",
    "        - inputs: 입력 텐서\n",
    "        \"\"\"\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d298db7b",
   "metadata": {},
   "source": [
    "Scaled Dot-Product Attention\n",
    "\n",
    "Query와 Key의 유사도를 계산하고, Value에 가중치를 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b350800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    \"\"\"\n",
    "    Scaled Dot-Product Attention 계산.\n",
    "    - query: Query 행렬\n",
    "    - key: Key 행렬\n",
    "    - value: Value 행렬\n",
    "    - mask: 패딩 마스크 (필요 시 적용)\n",
    "\n",
    "    반환값:\n",
    "    - output: 가중치가 적용된 Value 행렬\n",
    "    \"\"\"\n",
    "    # Query와 Key의 내적 계산\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # Key의 차원으로 스케일링\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # 마스크가 있다면 -∞ 값을 추가하여 무시\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # Softmax로 Attention 가중치 계산\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    # Attention 가중치를 Value에 곱함\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52335a5c",
   "metadata": {},
   "source": [
    "Multi-Head Attention 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40da755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        \"\"\"\n",
    "        Multi-Head Attention 초기화.\n",
    "        - d_model: 모델의 전체 차원\n",
    "        - num_heads: 헤드의 개수\n",
    "        \"\"\"\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # d_model이 num_heads로 나누어떨어지는지 확인\n",
    "        assert d_model % num_heads == 0\n",
    "\n",
    "        # 각 헤드의 차원\n",
    "        self.depth = d_model // num_heads\n",
    "\n",
    "        # Query, Key, Value를 위한 Dense 레이어\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        # 최종 출력 Dense 레이어\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        \"\"\"\n",
    "        입력 텐서를 다중 헤드로 분리.\n",
    "        - inputs: Dense 레이어 출력\n",
    "        - batch_size: 배치 크기\n",
    "        \"\"\"\n",
    "        # (batch_size, seq_len, d_model) -> (batch_size, seq_len, num_heads, depth)\n",
    "        inputs = tf.reshape(inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        # 헤드 축과 시퀀스 축을 교환\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Multi-Head Attention 계산.\n",
    "        - inputs: Query, Key, Value, Mask를 포함한 딕셔너리\n",
    "        \"\"\"\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # Query, Key, Value 생성 및 다중 헤드로 분리\n",
    "        query = self.split_heads(self.query_dense(query), batch_size)\n",
    "        key = self.split_heads(self.key_dense(key), batch_size)\n",
    "        value = self.split_heads(self.value_dense(value), batch_size)\n",
    "\n",
    "        # Scaled Dot-Product Attention 수행\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        # 헤드 통합\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "\n",
    "        # 최종 Dense 레이어 통과\n",
    "        return self.dense(concat_attention)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b34c58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359cc742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2392f978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8675bfbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2f45345",
   "metadata": {},
   "source": [
    "## 3. GPT 모델 구현\n",
    "\n",
    "GPT 모델은 Transformer 기반으로 하되, 인코더를 제거하고 디코더만 사용하여 생성 모델로 동작하도록 수정되었습니다. \n",
    "\n",
    "\n",
    "주요 변경 사항:\n",
    "\n",
    "- 인코더 제거: Transformer의 인코더-디코더 구조 중 인코더를 제거하고 디코더만 사용.\n",
    "- Look-Ahead Mask: GPT는 Causal Language Modeling을 위해 Look-Ahead Mask를 적용.\n",
    "- 위치 정보 추가: 입력 데이터에 위치 정보를 추가하는 PositionalEncoding 레이어 구현.\n",
    "- 학습 데이터 전처리: 디코더 입력과 출력 데이터를 시프트하여 구성."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d3ee8c",
   "metadata": {},
   "source": [
    "GPT Decoder Layer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "585b6057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT 모델 디코더 레이어 정의\n",
    "def decoder_layer_gpt(units, d_model, num_heads, dropout):\n",
    "    \"\"\"\n",
    "    GPT의 Decoder Layer를 정의.\n",
    "    - units: Feed Forward 네트워크의 은닉 유닛 크기\n",
    "    - d_model: 임베딩 차원\n",
    "    - num_heads: Multi-Head Attention의 헤드 개수\n",
    "    - dropout: 드롭아웃 비율\n",
    "    \"\"\"\n",
    "    # 입력 텐서 정의\n",
    "    inputs = tf.keras.Input(shape=(None, d_model))  # 입력 임베딩\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None))  # Look-ahead 마스크\n",
    "\n",
    "    # Multi-Head Attention\n",
    "    attention = MultiHeadAttention(d_model, num_heads)(\n",
    "        {'query': inputs, 'key': inputs, 'value': inputs, 'mask': look_ahead_mask}\n",
    "    )\n",
    "    # 잔차 연결과 Layer Normalization\n",
    "    attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + inputs)\n",
    "\n",
    "    # Feed Forward 네트워크\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "\n",
    "    # 잔차 연결과 Layer Normalization\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention)\n",
    "\n",
    "    # 모델 반환\n",
    "    return tf.keras.Model(inputs=[inputs, look_ahead_mask], outputs=outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680a9d48",
   "metadata": {},
   "source": [
    "Look-Ahead Mask 생성 함수\n",
    "\n",
    "Look-ahead Mask는 Transformer에서 미래 정보를 차단하는 데 사용됩니다. 상삼각 행렬로 구성된 마스크는 디코더가 현재 토큰 이후의 정보를 보지 못하게 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cb2d170",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(seq_len):\n",
    "    \"\"\"\n",
    "    Look-ahead 마스크 생성.\n",
    "    - seq_len: 시퀀스 길이\n",
    "    반환값:\n",
    "    - 상삼각 행렬로 이루어진 마스크 텐서\n",
    "    \"\"\"\n",
    "    return 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba417f4b",
   "metadata": {},
   "source": [
    "GPT 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dff6c52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_decoder(num_layers, units, d_model, num_heads, dropout, vocab_size, max_seq_len):\n",
    "    \"\"\"\n",
    "    GPT Decoder를 구성.\n",
    "    - num_layers: Decoder Layer의 개수\n",
    "    - units: Feed Forward 네트워크의 은닉 유닛 크기\n",
    "    - d_model: 임베딩 차원\n",
    "    - num_heads: Multi-Head Attention의 헤드 개수\n",
    "    - dropout: 드롭아웃 비율\n",
    "    - vocab_size: 단어 집합 크기\n",
    "    - max_seq_len: 최대 시퀀스 길이\n",
    "    \"\"\"\n",
    "    # 입력 정의\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')  # 정수형 시퀀스 입력\n",
    "\n",
    "    # 임베딩 및 위치 인코딩 추가\n",
    "    dec_inputs = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    x = PositionalEncoding(max_seq_len, d_model)(dec_inputs)\n",
    "\n",
    "    # Look-ahead Mask 생성\n",
    "    seq_len = tf.shape(inputs)[1]\n",
    "    look_ahead_mask = create_look_ahead_mask(seq_len)\n",
    "    look_ahead_mask = look_ahead_mask[tf.newaxis, tf.newaxis, :, :]  # 배치 차원 추가\n",
    "\n",
    "    # Decoder Layer 반복 적용\n",
    "    for _ in range(num_layers):\n",
    "        x = decoder_layer_gpt(units, d_model, num_heads, dropout)([x, look_ahead_mask])\n",
    "\n",
    "    # 출력 레이어: Vocab Size로 확장\n",
    "    outputs = tf.keras.layers.Dense(vocab_size)(x)  # Shape: (batch_size, sequence_length, vocab_size)\n",
    "\n",
    "    # 최종 모델 반환\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd671fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_38\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.shape_3 (TFOpLambd (2,)                 0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_6 (Sli ()                   0           tf.compat.v1.shape_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.ones_3 (TFOpLambda)          (None, None)         0           tf.__operators__.getitem_6[0][0] \n",
      "                                                                 tf.__operators__.getitem_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.linalg.band_part_3 (TFOpLamb (None, None)         0           tf.ones_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 768)    6399744     inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_3 (TFOpLambda) (None, None)         0           tf.linalg.band_part_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "positional_encoding_3 (Position (None, None, 768)    0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_7 (Sli (1, 1, None, None)   0           tf.math.subtract_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "model_26 (Functional)           (None, None, 768)    7087872     positional_encoding_3[0][0]      \n",
      "                                                                 tf.__operators__.getitem_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_27 (Functional)           (None, None, 768)    7087872     model_26[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_28 (Functional)           (None, None, 768)    7087872     model_27[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_29 (Functional)           (None, None, 768)    7087872     model_28[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_30 (Functional)           (None, None, 768)    7087872     model_29[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_31 (Functional)           (None, None, 768)    7087872     model_30[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_32 (Functional)           (None, None, 768)    7087872     model_31[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_33 (Functional)           (None, None, 768)    7087872     model_32[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_34 (Functional)           (None, None, 768)    7087872     model_33[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_35 (Functional)           (None, None, 768)    7087872     model_34[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_36 (Functional)           (None, None, 768)    7087872     model_35[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "model_37 (Functional)           (None, None, 768)    7087872     model_36[0][0]                   \n",
      "                                                                 tf.__operators__.getitem_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_218 (Dense)               (None, None, 8333)   6408077     model_37[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 97,862,285\n",
      "Trainable params: 97,862,285\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GPT 디코더 모델 생성\n",
    "gpt_model = gpt_decoder(\n",
    "    num_layers=12,      # 디코더 레이어의 개수(6->12)\n",
    "    units=3072,        # Feed Forward 네트워크의 은닉 유닛 크기(2048->3072)\n",
    "    d_model=768,       # 모델의 임베딩 차원 (768)\n",
    "    num_heads=12,       # Multi-Head Attention의 헤드 개수(8->12)\n",
    "    dropout=0.1,       # 드롭아웃 비율\n",
    "    vocab_size=VOCAB_SIZE,  # 단어 집합 크기\n",
    "    max_seq_len=MAX_LENGTH  # 최대 시퀀스 길이\n",
    ")\n",
    "\n",
    "'''\n",
    "    d_model=512,       # 모델의 임베딩 차원 (768)\n",
    "    num_heads=8,       # Multi-Head Attention의 헤드 개수(8->12)\n",
    "    GPU의 한계로 해당 변수로 실험 진행\n",
    "'''\n",
    "\n",
    "\n",
    "# 모델 요약 출력\n",
    "gpt_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3709fc5",
   "metadata": {},
   "source": [
    "Dataset 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e5f956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 데이터셋 크기와 배치 크기를 설정\n",
    "BUFFER_SIZE = 10000  # 데이터셋 크기만큼 설정 (적절히 조정 가능)\n",
    "BATCH_SIZE = 32      # 배치 크기 설정\n",
    "\n",
    "# 데이터셋 생성: 입력과 타깃 시퀀스 정의\n",
    "inputs = answers[:, :-1]  # 입력은 타깃의 마지막 토큰을 제외한 부분\n",
    "targets = answers[:, 1:]  # 타깃은 첫 번째 토큰을 제외한 부분\n",
    "\n",
    "# TensorFlow 데이터셋 생성\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {'inputs': inputs},  # 입력 시퀀스\n",
    "    targets               # 타깃 시퀀스\n",
    "))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7354306e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af95c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2d6f17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f98cb8d",
   "metadata": {},
   "source": [
    "## 4. 학습 데이터 및 모델 컴파일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c30144",
   "metadata": {},
   "source": [
    "학습률 스케줄러 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5cc6547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model=768\n",
    "\n",
    "# 커스텀 학습률 스케줄러\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "# 학습률 스케줄러 인스턴스 생성\n",
    "learning_rate = CustomSchedule(d_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be68c3d3",
   "metadata": {},
   "source": [
    "옵티마이저 및 손실 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4708684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam 옵티마이저 설정\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9\n",
    ")\n",
    "\n",
    "# 손실 함수 정의\n",
    "def loss_function(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    손실 함수 계산.\n",
    "    - y_true: 실제 값\n",
    "    - y_pred: 예측 값\n",
    "    \"\"\"\n",
    "    mask = tf.math.logical_not(tf.math.equal(y_true, 0))  # 패딩 마스크 생성\n",
    "    loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)\n",
    "    mask = tf.cast(mask, dtype=loss.dtype)  # 마스크 형변환\n",
    "    loss *= mask  # 마스크 적용\n",
    "    return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7468819f",
   "metadata": {},
   "source": [
    "모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a528ab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "\n",
    "# 모델 컴파일\n",
    "gpt_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_function,\n",
    "    metrics=[SparseCategoricalAccuracy(name='accuracy')]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e20e553",
   "metadata": {},
   "source": [
    "체크포인트 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "053caf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 체크포인트 디렉토리 설정\n",
    "checkpoint_path = \"./checkpoints/train\"\n",
    "os.makedirs(checkpoint_path, exist_ok=True)\n",
    "\n",
    "# 체크포인트 및 매니저 생성\n",
    "ckpt = tf.train.Checkpoint(transformer=gpt_model, optimizer=optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# 이전 체크포인트 복원\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print('이전 체크포인트 복원이 완료되었습니다!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4dd9e0",
   "metadata": {},
   "source": [
    "학습 루프 및 히스토리 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f9931be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 1/1 시작\n",
      "1378/1378 [==============================] - 344s 241ms/step - loss: 6.3051 - accuracy: 0.0273\n",
      "체크포인트 저장 완료: ./checkpoints/train/ckpt-1\n"
     ]
    }
   ],
   "source": [
    "# 학습 설정\n",
    "EPOCHS = 1  # 학습 에포크 수\n",
    "history_data = {'loss': [], 'accuracy': []}  # 학습 기록 저장용\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"에포크 {epoch + 1}/{EPOCHS} 시작\")\n",
    "    \n",
    "    # 모델 학습\n",
    "    history = gpt_model.fit(\n",
    "        dataset,\n",
    "        epochs=1  # 에포크별로 수행\n",
    "    )\n",
    "    \n",
    "    # 학습 기록 저장\n",
    "    history_data['loss'].append(history.history['loss'][0])\n",
    "    history_data['accuracy'].append(history.history['accuracy'][0])\n",
    "    \n",
    "    # 체크포인트 저장\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print(f\"체크포인트 저장 완료: {ckpt_save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa77389",
   "metadata": {},
   "source": [
    "## 5. 학습 데이터 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59fd7de",
   "metadata": {},
   "source": [
    "디코더 추론 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2bad2d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "    \"\"\"\n",
    "    입력 문장을 GPT 모델을 사용해 정수 시퀀스로 변환.\n",
    "    - sentence: 입력 문장 (문자열)\n",
    "    반환값: 예측된 정수 시퀀스 (NumPy 배열)\n",
    "    \"\"\"\n",
    "    # 입력 문장 전처리\n",
    "    sentence = preprocess_sentence(sentence)  # 불필요한 문자 제거 및 소문자화\n",
    "    sentence = START_TOKEN + tokenizer.encode(sentence) + END_TOKEN  # 토큰화 및 시작/끝 토큰 추가\n",
    "    sentence = tf.expand_dims(sentence, axis=0)  # 배치 차원 추가\n",
    "\n",
    "    # 초기 출력 설정\n",
    "    output = tf.expand_dims(START_TOKEN, 0)  # 시작 토큰 추가, Shape: (1, 1)\n",
    "    output = tf.cast(output, dtype=tf.int32)  # 데이터 타입 지정\n",
    "\n",
    "    # MAX_LENGTH 만큼 반복하여 시퀀스를 생성\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # GPT 모델에 입력\n",
    "        predictions = gpt_model({'inputs': output}, training=False)\n",
    "\n",
    "        # 마지막 토큰의 확률 분포 추출\n",
    "        predictions = predictions[:, -1:, :]  # Shape: (batch_size, 1, vocab_size)\n",
    "\n",
    "        # 가장 높은 확률을 가진 토큰의 ID 선택\n",
    "        predicted_id = tf.argmax(predictions, axis=-1, output_type=tf.int32)\n",
    "\n",
    "        # 예측된 토큰을 출력 시퀀스에 추가\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "        # END_TOKEN을 예측하면 루프 종료\n",
    "        if predicted_id == END_TOKEN[0]:\n",
    "            break\n",
    "\n",
    "    # 최종 시퀀스 반환 (배치 차원 제거)\n",
    "    return tf.squeeze(output, axis=0).numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f654cf8",
   "metadata": {},
   "source": [
    "문장 생성 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c0aa8e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "    \"\"\"\n",
    "    입력 문장에 대한 GPT 디코더의 응답 생성.\n",
    "    - sentence: 입력 문장 (문자열)\n",
    "    반환값: 생성된 응답 문장 (문자열)\n",
    "    \"\"\"\n",
    "    # 디코더를 사용해 정수 시퀀스 예측\n",
    "    prediction = decoder_inference(sentence)\n",
    "\n",
    "    # 정수 시퀀스를 텍스트로 디코딩\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [i for i in prediction if i < tokenizer.vocab_size]  # 단어 집합 크기 이하의 토큰만 디코딩\n",
    "    )\n",
    "\n",
    "    # 입력 및 출력 문장 출력\n",
    "    print('Input:', sentence)\n",
    "    print('Output:', predicted_sentence)\n",
    "\n",
    "    return predicted_sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1f88ce",
   "metadata": {},
   "source": [
    "모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c61f8b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Where have you been?\n",
      "Output: i i i i \n",
      "Input: It's a trap\n",
      "Output: i i i i \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i i i i '"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예시 문장으로 챗봇 응답 확인\n",
    "sentence_generation('Where have you been?')\n",
    "sentence_generation(\"It's a trap\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b4976e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2318a59c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55369dee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1825971c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245c8b58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b617d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8884ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb57aa65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10355e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b60b9b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb35cefd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456228b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731194fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920cf20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a75753e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7be90ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa12a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e86e87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa805cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef92186e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3279384a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdcf1dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4343d65c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71abc1a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289568af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb5bead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ad5a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ecb0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e95679c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936cc5a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc05724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0ad75d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6971f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c967e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6daf100",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
